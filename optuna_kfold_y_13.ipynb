{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optuna_kfold_y_13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0subtCBfIVK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "ZkmftlGFfK9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(42) # Seed 고정\n",
        "\n",
        "def lg_nrmse(gt, preds):\n",
        "    # 각 Y Feature별 NRMSE 총합\n",
        "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
        "    all_nrmse = []\n",
        "    for idx in range(0,13): # ignore 'ID'\n",
        "        rmse = mean_squared_error(np.array(gt)[:,idx], preds[:,idx], squared=False)\n",
        "        nrmse = rmse/np.mean(np.abs(np.array(gt)[:,idx]))\n",
        "        all_nrmse.append(nrmse)\n",
        "    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:15])\n",
        "    return score"
      ],
      "metadata": {
        "id": "e9QjFulXfTnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lg_nrmse_one(gt, preds):\n",
        "    # Y_08의 경우는 가중치 1.2 부여. 8 이후부터는 모두 가중치 1.0\n",
        "    all_nrmse = []\n",
        "    rmse = mean_squared_error(np.array(gt), preds, squared=False)\n",
        "    nrmse = rmse/np.mean(np.abs(np.array(gt)))\n",
        "    all_nrmse.append(nrmse)\n",
        "    score = 1.0 * np.sum(all_nrmse)\n",
        "    return score\n",
        "\n",
        "#얘를 쓸것!!!"
      ],
      "metadata": {
        "id": "yDO_R046fUna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/LG/train.csv').drop(columns=\"ID\")\n",
        "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
        "train_x=train_x.drop(columns=['X_04','X_23','X_47','X_48'])\n",
        "train_y = train_df.filter(regex='Y') # Output : Y Feature"
      ],
      "metadata": {
        "id": "bDByrpp7fVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Y_02\n"
      ],
      "metadata": {
        "id": "xaNuhkCBfYKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y13 = train_y['Y_13']\n",
        "train_y13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgsxKKdSfau4",
        "outputId": "8255c94c-9fc1-4ac2-b7c5-502520e4f8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.456\n",
              "1        1.184\n",
              "2        0.665\n",
              "3        1.079\n",
              "4        0.646\n",
              "         ...  \n",
              "39602    1.215\n",
              "39603    0.606\n",
              "39604    1.154\n",
              "39605    0.187\n",
              "39606    0.348\n",
              "Name: Y_02, Length: 39607, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y13 = pd.DataFrame(train_y13, index= train_y.index)\n",
        "train_y13"
      ],
      "metadata": {
        "id": "AhZ9ZiU0fWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#클리핑"
      ],
      "metadata": {
        "id": "5yOQ1BAYfqP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------------\n",
        "# 열마다 학습 데이터의 1%, 99% 지점을 확인\n",
        "p01 = train_x.quantile(0.01)\n",
        "p99 = train_x.quantile(0.99)\n",
        "\n",
        "# 1％점 이하의 값은 1%점으로, 99%점 이상의 값은 99%점으로 클리핑\n",
        "train_x = train_x.clip(p01, p99, axis=1)"
      ],
      "metadata": {
        "id": "Vzjikt4Zfq_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 커넥터 핀 휨 \n",
        "train_x['X__21'] = (train_x['X_24'] - train_x['X_12'])\n",
        "train_x['X__22'] = (train_x['X_25'] - train_x['X_12'])\n",
        "train_x['X__23'] = (train_x['X_26'] - train_x['X_12'])\n",
        "train_x['X__24'] = (train_x['X_27'] - train_x['X_12'])\n",
        "train_x['X__25'] = (train_x['X_28'] - train_x['X_12'])\n",
        "train_x['X__26'] = (train_x['X_29'] - train_x['X_12'])\n",
        "#이후, RFE 상에서 혹여나 새로운 변수를 만드는데 기여한 기존 변수들(12, 24,25,26,27,28,29)가 important하게 잡힐 수 있으므로 일단은 놔둡니다.\n",
        "#또한, 현재 train_x 상에서는 통과여부 변수들은 모두 drop된 상태입니다."
      ],
      "metadata": {
        "id": "N_Tg1klnfsSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbcols= ['X_20', 'X_32', 'X_30', 'X_07', 'X_49', 'X_03', 'X_21', 'X_22', 'X_09', 'X_08', 'X_19', 'X__23', 'X_05', \n",
        "          'X_45', 'X_06', 'X_14', 'X_54', 'X_51', 'X_55', 'X_53', 'X_52', 'X__25', 'X_16', 'X__21', 'X_40', 'X_25', 'X_42']\n",
        "\n",
        "train_set = train_x[xgbcols]\n",
        "train_set"
      ],
      "metadata": {
        "id": "hXY1OkMefuFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "ab0a7579-631b-477a-a1f5-4ef2256fdfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       X_22  X_13   X_07   X_18   X_03   X_43    X_06  X__22     X_05  \\\n",
              "0      3.13  0.18  29.45  13.44  67.47  21.28  74.983  -2.27  101.892   \n",
              "1      3.20  0.18  28.73  13.42  65.17  21.16  72.943  -2.28  101.944   \n",
              "2      3.12  0.15  28.81  13.43  64.07  21.17  72.943  -2.30  103.153   \n",
              "3      3.08  0.21  28.92  13.40  67.57  21.20  76.002  -2.28  101.971   \n",
              "4      3.12  0.16  29.68  13.42  63.57  21.18  70.904  -2.29  101.981   \n",
              "...     ...   ...    ...    ...    ...    ...     ...    ...      ...   \n",
              "39602  3.13  0.15  30.20  13.46  62.27  21.19  66.825  -2.25  103.150   \n",
              "39603  3.06  0.13  29.21  13.44  62.77  21.21  66.825  -2.28  102.021   \n",
              "39604  3.12  0.14  29.96  13.46  64.67  21.22  68.864  -2.29  103.144   \n",
              "39605  3.09  0.16  30.30  13.46  63.67  21.16  67.845  -2.30  102.025   \n",
              "39606  3.10  0.14  30.16  13.47  65.67  21.18  69.884  -2.28  102.004   \n",
              "\n",
              "            X_49    X_09   X_14  X_32   X_17  X_19  X__24  X_45  X_20  X_21  \n",
              "0       9706.030  245.71  13.34  1.46  13.52  3.11  -2.28  0.26  3.17  3.06  \n",
              "1      10423.430  233.61  13.33  1.45  13.51  3.04  -2.28  0.13  3.11  2.98  \n",
              "2      10948.530  272.20  13.36  1.46  13.51  3.04  -2.29  0.14  3.04  3.01  \n",
              "3      15007.030  255.36  13.30  1.47  13.51  3.05  -2.27  0.22  3.01  3.02  \n",
              "4      11051.030  241.46  13.35  1.47  13.50  3.04  -2.23  0.22  3.07  3.00  \n",
              "...          ...     ...    ...   ...    ...   ...    ...   ...   ...   ...  \n",
              "39602  56583.294  298.05  13.37  1.36  13.52  3.20  -2.25  0.11  3.03  3.06  \n",
              "39603  56583.294  270.67  13.36  1.37  13.49  3.15  -2.28  0.12  3.06  3.05  \n",
              "39604   9092.372  198.07  13.38  1.37  13.52  3.23  -2.31  0.13  3.09  3.07  \n",
              "39605  56583.294  275.52  13.36  1.36  13.52  3.18  -2.28  0.11  3.01  3.15  \n",
              "39606  56583.294  276.06  13.39  1.36  13.52  3.11  -2.33  0.11  3.05  3.03  \n",
              "\n",
              "[39607 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85e47283-60a2-4560-9dda-e1e6432453b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_22</th>\n",
              "      <th>X_13</th>\n",
              "      <th>X_07</th>\n",
              "      <th>X_18</th>\n",
              "      <th>X_03</th>\n",
              "      <th>X_43</th>\n",
              "      <th>X_06</th>\n",
              "      <th>X__22</th>\n",
              "      <th>X_05</th>\n",
              "      <th>X_49</th>\n",
              "      <th>X_09</th>\n",
              "      <th>X_14</th>\n",
              "      <th>X_32</th>\n",
              "      <th>X_17</th>\n",
              "      <th>X_19</th>\n",
              "      <th>X__24</th>\n",
              "      <th>X_45</th>\n",
              "      <th>X_20</th>\n",
              "      <th>X_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>29.45</td>\n",
              "      <td>13.44</td>\n",
              "      <td>67.47</td>\n",
              "      <td>21.28</td>\n",
              "      <td>74.983</td>\n",
              "      <td>-2.27</td>\n",
              "      <td>101.892</td>\n",
              "      <td>9706.030</td>\n",
              "      <td>245.71</td>\n",
              "      <td>13.34</td>\n",
              "      <td>1.46</td>\n",
              "      <td>13.52</td>\n",
              "      <td>3.11</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>0.26</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.20</td>\n",
              "      <td>0.18</td>\n",
              "      <td>28.73</td>\n",
              "      <td>13.42</td>\n",
              "      <td>65.17</td>\n",
              "      <td>21.16</td>\n",
              "      <td>72.943</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>101.944</td>\n",
              "      <td>10423.430</td>\n",
              "      <td>233.61</td>\n",
              "      <td>13.33</td>\n",
              "      <td>1.45</td>\n",
              "      <td>13.51</td>\n",
              "      <td>3.04</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>0.13</td>\n",
              "      <td>3.11</td>\n",
              "      <td>2.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.12</td>\n",
              "      <td>0.15</td>\n",
              "      <td>28.81</td>\n",
              "      <td>13.43</td>\n",
              "      <td>64.07</td>\n",
              "      <td>21.17</td>\n",
              "      <td>72.943</td>\n",
              "      <td>-2.30</td>\n",
              "      <td>103.153</td>\n",
              "      <td>10948.530</td>\n",
              "      <td>272.20</td>\n",
              "      <td>13.36</td>\n",
              "      <td>1.46</td>\n",
              "      <td>13.51</td>\n",
              "      <td>3.04</td>\n",
              "      <td>-2.29</td>\n",
              "      <td>0.14</td>\n",
              "      <td>3.04</td>\n",
              "      <td>3.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.08</td>\n",
              "      <td>0.21</td>\n",
              "      <td>28.92</td>\n",
              "      <td>13.40</td>\n",
              "      <td>67.57</td>\n",
              "      <td>21.20</td>\n",
              "      <td>76.002</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>101.971</td>\n",
              "      <td>15007.030</td>\n",
              "      <td>255.36</td>\n",
              "      <td>13.30</td>\n",
              "      <td>1.47</td>\n",
              "      <td>13.51</td>\n",
              "      <td>3.05</td>\n",
              "      <td>-2.27</td>\n",
              "      <td>0.22</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>29.68</td>\n",
              "      <td>13.42</td>\n",
              "      <td>63.57</td>\n",
              "      <td>21.18</td>\n",
              "      <td>70.904</td>\n",
              "      <td>-2.29</td>\n",
              "      <td>101.981</td>\n",
              "      <td>11051.030</td>\n",
              "      <td>241.46</td>\n",
              "      <td>13.35</td>\n",
              "      <td>1.47</td>\n",
              "      <td>13.50</td>\n",
              "      <td>3.04</td>\n",
              "      <td>-2.23</td>\n",
              "      <td>0.22</td>\n",
              "      <td>3.07</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39602</th>\n",
              "      <td>3.13</td>\n",
              "      <td>0.15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>13.46</td>\n",
              "      <td>62.27</td>\n",
              "      <td>21.19</td>\n",
              "      <td>66.825</td>\n",
              "      <td>-2.25</td>\n",
              "      <td>103.150</td>\n",
              "      <td>56583.294</td>\n",
              "      <td>298.05</td>\n",
              "      <td>13.37</td>\n",
              "      <td>1.36</td>\n",
              "      <td>13.52</td>\n",
              "      <td>3.20</td>\n",
              "      <td>-2.25</td>\n",
              "      <td>0.11</td>\n",
              "      <td>3.03</td>\n",
              "      <td>3.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39603</th>\n",
              "      <td>3.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>29.21</td>\n",
              "      <td>13.44</td>\n",
              "      <td>62.77</td>\n",
              "      <td>21.21</td>\n",
              "      <td>66.825</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>102.021</td>\n",
              "      <td>56583.294</td>\n",
              "      <td>270.67</td>\n",
              "      <td>13.36</td>\n",
              "      <td>1.37</td>\n",
              "      <td>13.49</td>\n",
              "      <td>3.15</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>0.12</td>\n",
              "      <td>3.06</td>\n",
              "      <td>3.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39604</th>\n",
              "      <td>3.12</td>\n",
              "      <td>0.14</td>\n",
              "      <td>29.96</td>\n",
              "      <td>13.46</td>\n",
              "      <td>64.67</td>\n",
              "      <td>21.22</td>\n",
              "      <td>68.864</td>\n",
              "      <td>-2.29</td>\n",
              "      <td>103.144</td>\n",
              "      <td>9092.372</td>\n",
              "      <td>198.07</td>\n",
              "      <td>13.38</td>\n",
              "      <td>1.37</td>\n",
              "      <td>13.52</td>\n",
              "      <td>3.23</td>\n",
              "      <td>-2.31</td>\n",
              "      <td>0.13</td>\n",
              "      <td>3.09</td>\n",
              "      <td>3.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39605</th>\n",
              "      <td>3.09</td>\n",
              "      <td>0.16</td>\n",
              "      <td>30.30</td>\n",
              "      <td>13.46</td>\n",
              "      <td>63.67</td>\n",
              "      <td>21.16</td>\n",
              "      <td>67.845</td>\n",
              "      <td>-2.30</td>\n",
              "      <td>102.025</td>\n",
              "      <td>56583.294</td>\n",
              "      <td>275.52</td>\n",
              "      <td>13.36</td>\n",
              "      <td>1.36</td>\n",
              "      <td>13.52</td>\n",
              "      <td>3.18</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>0.11</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39606</th>\n",
              "      <td>3.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>30.16</td>\n",
              "      <td>13.47</td>\n",
              "      <td>65.67</td>\n",
              "      <td>21.18</td>\n",
              "      <td>69.884</td>\n",
              "      <td>-2.28</td>\n",
              "      <td>102.004</td>\n",
              "      <td>56583.294</td>\n",
              "      <td>276.06</td>\n",
              "      <td>13.39</td>\n",
              "      <td>1.36</td>\n",
              "      <td>13.52</td>\n",
              "      <td>3.11</td>\n",
              "      <td>-2.33</td>\n",
              "      <td>0.11</td>\n",
              "      <td>3.05</td>\n",
              "      <td>3.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39607 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85e47283-60a2-4560-9dda-e1e6432453b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85e47283-60a2-4560-9dda-e1e6432453b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85e47283-60a2-4560-9dda-e1e6432453b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "LaHYiSY6-VDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import time\n",
        "from optuna import Trial, visualization\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "#XGB 하이퍼 파라미터들 값 지정\n",
        "def objectiveXGB(trial: Trial, X, y):  # X : train_set, y = train_y13\n",
        "\n",
        "    param = {\n",
        "        \"n_estimators\" : trial.suggest_int('n_estimators', 1000, 5000),\n",
        "        'max_depth':trial.suggest_int('max_depth', 5, 20),\n",
        "        'min_child_weight':trial.suggest_int('min_child_weight', 1, 20),\n",
        "        'gamma':trial.suggest_int('gamma', 0, 1.0),\n",
        "        'learning_rate': trial.suggest_discrete_uniform('learning_rate',0.001,0.01,0.0005),\n",
        "        'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.05),\n",
        "        'nthread' : -1,\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0])\n",
        "    }\n",
        "\n",
        "    kf = KFold(shuffle=True, n_splits=5, random_state=42)\n",
        "    loss = []\n",
        "    i = 0\n",
        "\n",
        "    # 데이터 나누기\n",
        "    X, y = X.values, y.values\n",
        "    for (train_index, test_index) in kf.split(X):\n",
        "        since = time.time()\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # 설정된 파라미터 적용\n",
        "        model = xgb.XGBRegressor(**param)\n",
        "\n",
        "        # 학습하기\n",
        "        xgb_model = model.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n",
        "\n",
        "        # 평가 및 기록\n",
        "        elapsed = time.time() - since\n",
        "        score = lg_nrmse_one(y_test, xgb_model.predict(X_test))\n",
        "        print(\"Fold {} | NRMSE : {:.6f}, Elapsed Time: {:.4f}\".format(i, score, elapsed))\n",
        "        loss.append(score)\n",
        "        i += 1\n",
        "\n",
        "    print(\"Best: {:.6f}, Avg:{:.6f}\".format(min(loss), np.mean(loss)))\n",
        "\n",
        "    return np.mean(loss)"
      ],
      "metadata": {
        "id": "ZHo2rZqbvSXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# MAE가 최소가 되는 방향으로 학습을 진행\n",
        "# TPESampler : Sampler using TPE (Tree-structured Parzen Estimator) algorithm.\n",
        "\n",
        "# x_train, x_valid, y_train, y_valid = train_test_split(train_x_xgb, train_y01, test_size=0.3) \n",
        "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
        "\n",
        "# n_trials 지정해주지 않으면, 무한 반복\n",
        "study.optimize(lambda trial : objectiveXGB(trial, train_set, train_y13), n_trials = 100)\n",
        "\n",
        "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
        "print('study.best_params:', study.best_trial.value)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "print('study.best_params:', study.best_params)"
      ],
      "metadata": {
        "id": "KqgLKFJbvTRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/LG/test.csv').drop(columns=\"ID\")\n",
        "\n",
        "test_x = test_x.drop(columns=['X_04','X_23','X_47','X_48'])\n",
        "\n",
        "test_x = test_x.clip(p01, p99, axis=1)\n",
        "\n",
        "# 커넥터 핀 휨 \n",
        "test_x['X__21'] = (test_x['X_24'] - test_x['X_12'])\n",
        "test_x['X__22'] = (test_x['X_25'] - test_x['X_12'])\n",
        "test_x['X__23'] = (test_x['X_26'] - test_x['X_12'])\n",
        "test_x['X__24'] = (test_x['X_27'] - test_x['X_12'])\n",
        "test_x['X__25'] = (test_x['X_28'] - test_x['X_12'])\n",
        "test_x['X__26'] = (test_x['X_29'] - test_x['X_12'])\n",
        "\n",
        "test_x=test_x[xgbcols]\n",
        "#이후, RFE 상에서 혹여나 새로운 변수를 만드는데 기여한 기존 변수들(12, 24,25,26,27,28,29)가 important하게 잡힐 수 있으므로 일단은 놔둡니다.\n",
        "#또한, 현재 train_x 상에서는 통과여부 변수들은 모두 drop된 상태입니다.\n",
        "\n",
        "XGB = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, gamma=1, subsample=0.75,\n",
        "                           colsample_bytree=1, max_depth=7)\n",
        "\n",
        "XGB.fit(train_set, train_y13)\n",
        "\n",
        "y_pred =XGB.predict(test_x)\n",
        "\n",
        "submit = pd.DataFrame(y_pred, index= test_x.index, columns = ['Y_13'])"
      ],
      "metadata": {
        "id": "Glp51om0fo-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ea76ed-3a0f-4e47-ed8e-86efe03c8466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:52:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit"
      ],
      "metadata": {
        "id": "MHJi5QXuH-BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('/content/drive/MyDrive/Colab Notebooks/LG/submit_y_13.csv', index=False)"
      ],
      "metadata": {
        "id": "W9RphlfKrFy7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}